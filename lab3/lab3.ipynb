{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 1: Working with a dataset with categorical features"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1, Reading the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\wilux\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn as sk\n",
    "import krippendorff\n",
    "import torch \n",
    "\n",
    "class TDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, encodings, labels=None):\n",
    "        self.encodings = encodings\n",
    "        self.labels = labels\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
    "        if self.labels:\n",
    "            item[\"labels\"] = torch.tensor(self.labels[idx])\n",
    "        return item\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.encodings[\"input_ids\"])\n",
    "    \n",
    "class DataSetContainer():\n",
    "    def __init__(self, RawY=None, RawX=None, File=None, Consensus=None, SplitY=None, ConfidenceWeights=None):\n",
    "        self.RawX = RawX\n",
    "        self.RawY = RawY\n",
    "        self.SplitY = SplitY\n",
    "        self.File = File\n",
    "        self.Consensus = Consensus\n",
    "        self.ConfidenceWeights = ConfidenceWeights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainContainer = DataSetContainer(File=\"assets/a3_train_final.tsv\")\n",
    "testContainer = DataSetContainer(File=\"assets/a3_test.tsv\")\n",
    "dataContainers = [trainContainer, testContainer]\n",
    "\n",
    "for dcont in dataContainers:\n",
    "    df = pd.read_table(dcont.File, names=['opinion', 'text'])\n",
    "    df = df.sample(frac=1, random_state=1337)\n",
    "    df[\"text\"] = df[\"text\"].apply(lambda a:a.lower())\n",
    "    dcont.RawY = df[\"opinion\"]\n",
    "    dcont.RawX = df[\"text\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "annotator class distribution for for taining data is {'1': 37854, '0': 38328, '-1': 3730}\n",
      "Krippendorff alpha for training data: 0.8798749025443741\n"
     ]
    }
   ],
   "source": [
    "# The trainset has annotator disagreements\n",
    "# https://towardsdatascience.com/assessing-annotator-disagreements-in-python-to-build-a-robust-dataset-for-machine-learning-16c74b49f043\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import random\n",
    "from collections import Counter\n",
    "allNums = trainContainer.RawY.str.split('/').to_numpy()\n",
    "allNums = np.concatenate(allNums).ravel().tolist()\n",
    "occNum = dict(Counter(allNums))\n",
    "print(f\"annotator class distribution for for taining data is {occNum}\")\n",
    "del occNum['-1']\n",
    "\n",
    "\n",
    "def randomByOcc():\n",
    "    val,prob = zip(*(occNum.items()))\n",
    "    #return int(random.choices([0,1], weights=[1,9]))\n",
    "    return int(random.choices(val,weights=prob))\n",
    "\n",
    "def toNumOrNan(n):\n",
    "    try:\n",
    "        if (n == \"-1\"):\n",
    "            #return randomByOcc()\n",
    "            #return 0\n",
    "            return np.nan\n",
    "        return int(n)\n",
    "    except Exception:\n",
    "        return np.nan\n",
    "\n",
    "for dset in [trainContainer]:\n",
    "    splitOpinion = dset.RawY.str.split('/', expand=True)\n",
    "    splitOpinion = splitOpinion.applymap(toNumOrNan).transpose()\n",
    "    \n",
    "    # since we don't know who the annotators are who wrote what should be arbitrary\n",
    "    # but (it does not actually matter for krippendorf)\n",
    "    #splitOpinion = pd.DataFrame(data=[sk.utils.shuffle(list(splitOpinion.loc[:,c]), random_state=c) for c in splitOpinion.columns]).transpose()\n",
    "\n",
    "    dset.SplitY = splitOpinion\n",
    "    dset.Consensus = krippendorff.alpha(reliability_data=splitOpinion, value_domain=[0,1])\n",
    "print(f\"Krippendorff alpha for training data: {trainContainer.Consensus}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Weiging annotations, https://arxiv.org/pdf/2208.06161.pdf\n",
    "#   SPA makes one key assumption: The degree to\n",
    "#   which labels are absent must be independent of the\n",
    "#   true item-agreements ni⊥Pi.\n",
    "from collections import Counter\n",
    "\n",
    "def getMostLikelyAndItsWeight(col):\n",
    "    answer2count = Counter([x for x in col if x in [0,1]])\n",
    "    nAnnotators = float(len(answer2count))\n",
    "\n",
    "    mostPopularAnswer = sorted(answer2count, reverse=True)[0]\n",
    "    mostPopularCount = answer2count[mostPopularAnswer]\n",
    "\n",
    "    # agreement = % is the most popular - % isn't the most popular\n",
    "    del answer2count[mostPopularAnswer]\n",
    "    agreement = float(mostPopularCount - sum(answer2count.values()))/nAnnotators\n",
    "\n",
    "    #using weight = number of annotators\n",
    "    weight = nAnnotators\n",
    "\n",
    "    return (weight*agreement, mostPopularAnswer)\n",
    "\n",
    "train_weights,train_mostPopClass = zip(*[\n",
    "    getMostLikelyAndItsWeight(dset.SplitY.loc[:,c]) \n",
    "    for c in trainContainer.SplitY.columns\n",
    "])\n",
    "trainContainer.ConfidenceWeights = pd.Series(list(train_weights))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 770x380 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# input annotator distribution\n",
    "def showAnnotatorDistribution(trainContainer):\n",
    "    dstr = trainContainer.RawY.apply(lambda ls: len(ls.split(\"/\")))\n",
    "    counts = Counter(dstr)\n",
    "    val, amount = zip(*(sorted(counts.items())))\n",
    "\n",
    "    fig, (ax, ax2) = plt.subplots(2, 1, sharex=True)\n",
    "    fig.set_size_inches(7.7, 3.8)\n",
    "\n",
    "    ax.set_ylim(31500, 35000)  # outliers only\n",
    "    ax2.set_ylim(0, 3500)  # most of the data\n",
    "\n",
    "    ax.spines['bottom'].set_visible(False)\n",
    "    ax2.spines['top'].set_visible(False)\n",
    "    ax.xaxis.tick_top()\n",
    "    ax.tick_params(labeltop=False)  # don't put tick labels at the top\n",
    "    ax2.xaxis.tick_bottom()\n",
    "\n",
    "    d = .01  # how big to make the diagonal lines in axes coordinates\n",
    "    # arguments to pass to plot, just so we don't keep repeating them\n",
    "    kwargs = dict(transform=ax.transAxes, color='k', clip_on=False)\n",
    "    ax.plot((-d, +d), (-d, +d), **kwargs)        # top-left diagonal\n",
    "    ax.plot((1 - d, 1 + d), (-d, +d), **kwargs)  # top-right diagonal\n",
    "    kwargs.update(transform=ax2.transAxes)  # switch to the bottom axes\n",
    "    ax2.plot((-d, +d), (1 - d, 1 + d), **kwargs)  # bottom-left diagonal\n",
    "    ax2.plot((1 - d, 1 + d), (1 - d, 1 + d), **kwargs)  # bottom-right diagonal\n",
    "\n",
    "    fig.supxlabel(\"Number of annotations\")\n",
    "    fig.supylabel(\"Occurences\")\n",
    "\n",
    "    ax.bar(val, amount)\n",
    "    ax2.bar(val, amount)\n",
    "    \n",
    "showAnnotatorDistribution(trainContainer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.seq_relationship.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.weight']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "############\n",
    "# Bert Setup\n",
    "############\n",
    "from transformers import BertTokenizer, BertForSequenceClassification\n",
    "\n",
    "bertTokenizer = BertTokenizer.from_pretrained(\n",
    "    'bert-base-uncased'\n",
    ")\n",
    "bertModel = BertForSequenceClassification.from_pretrained(\n",
    "    \"bert-base-uncased\",\n",
    "    num_labels=2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# max tweet = 240 characters -> 120 words\n",
    "# must const sizes or torch gets angry\n",
    "from sklearn.model_selection import train_test_split \n",
    "X_train, X_val, y_train, y_val = train_test_split(trainContainer.RawX, train_mostPopClass, test_size=0.2)\n",
    "\n",
    "train_Xtoken = bertTokenizer(list(X_train), max_length=120, padding=True, truncation=True) \n",
    "eval_Xtoken  = bertTokenizer(list(X_val),  max_length=120, padding=True, truncation=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30308\n",
      "30308\n",
      "30308\n",
      "30308\n"
     ]
    }
   ],
   "source": [
    "trainY = [int(x) for x in list(y_train)]\n",
    "evalY = [int(x) for x in list(y_val)]\n",
    "\n",
    "trainTset = TDataset(train_Xtoken, trainY)\n",
    "evalTset = TDataset(eval_Xtoken, evalY)\n",
    "\n",
    "#Making sure sizes are correct\n",
    "print(len(train_Xtoken[\"input_ids\"]))\n",
    "print(len(train_Xtoken[\"token_type_ids\"]))\n",
    "print(len(train_Xtoken[\"attention_mask\"]))\n",
    "print(len(trainY))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getScores(torchDataSet):\n",
    "    pred, labels = torchDataSet\n",
    "    pred = np.argmax(pred, axis=1)\n",
    "\n",
    "    recall = sk.metrics.recall_score(y_true=labels, y_pred=pred)\n",
    "    precision = sk.metrics.precision_score(y_true=labels, y_pred=pred)\n",
    "    f1 = sk.metrics.f1_score(y_true=labels, y_pred=pred)\n",
    "\n",
    "    return {\n",
    "        \"precision\": precision, \n",
    "        \"recall\": recall, \n",
    "        \"f1\": f1\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import TrainingArguments, Trainer\n",
    "from transformers import EarlyStoppingCallback\n",
    "\n",
    "#https://towardsdatascience.com/fine-tuning-pretrained-nlp-models-with-huggingfaces-trainer-6326a4456e7b\n",
    "args = TrainingArguments(\n",
    "    output_dir=\"output\",\n",
    "    evaluation_strategy=\"steps\",\n",
    "    eval_steps=500,\n",
    "    per_device_train_batch_size=8,\n",
    "    per_device_eval_batch_size=8,\n",
    "    num_train_epochs=3,\n",
    "    seed=1337,\n",
    "    load_best_model_at_end=True,\n",
    ")\n",
    "trainer = Trainer(\n",
    "    model=bertModel,\n",
    "    args=args,\n",
    "    train_dataset=trainTset,\n",
    "    eval_dataset=evalTset,\n",
    "    compute_metrics=getScores,\n",
    "    callbacks=[EarlyStoppingCallback(early_stopping_patience=3)],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"WANDB_DISABLED\"] = \"true\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#RUN \n",
    "#trainer.train()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file output/checkpoint-4500\\config.json\n",
      "Model config BertConfig {\n",
      "  \"_name_or_path\": \"bert-base-uncased\",\n",
      "  \"architectures\": [\n",
      "    \"BertForSequenceClassification\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"problem_type\": \"single_label_classification\",\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.26.1\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "loading weights file output/checkpoint-4500\\pytorch_model.bin\n",
      "All model checkpoint weights were used when initializing BertForSequenceClassification.\n",
      "\n",
      "All the weights of BertForSequenceClassification were initialized from the model checkpoint at output/checkpoint-4500.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use BertForSequenceClassification for predictions without further training.\n",
      "No `TrainingArguments` passed, using `output_dir=tmp_trainer`.\n",
      "PyTorch: setting up devices\n",
      "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n",
      "Using the `WANDB_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).\n"
     ]
    }
   ],
   "source": [
    "trainedPath = \"output/checkpoint-4500\"\n",
    "trainedModel = BertForSequenceClassification.from_pretrained(trainedPath, num_labels=2)\n",
    "\n",
    "test_trainer = Trainer(\n",
    "    model=trainedModel\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "nTake = min(100, len(testContainer.RawX))\n",
    "\n",
    "test_X = list(testContainer.RawX)[:nTake]\n",
    "test_Xtoken = bertTokenizer(list(testContainer.RawX)[:nTake], max_length=120, padding=True, truncation=True) \n",
    "testYtrue = [int(x) for x in list(testContainer.RawY)[:nTake]] # no split consensus for test\n",
    "\n",
    "testTset = TDataset(test_Xtoken)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test_X = X_train\n",
    "#testYtrue = y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Prediction *****\n",
      "  Num examples = 100\n",
      "  Batch size = 8\n",
      "100%|██████████| 13/13 [00:18<00:00,  1.40s/it]\n"
     ]
    }
   ],
   "source": [
    "raw_pred, _, _ = test_trainer.predict(testTset)\n",
    "#raw_pred, _, _ = test_trainer.predict(trainTset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = np.argmax(raw_pred, axis=1)\n",
    "\n",
    "df = pd.DataFrame()\n",
    "df[\"text\"] = test_X\n",
    "df[\"true_opinion\"] = testYtrue\n",
    "df[\"predicted_opinion\"] = y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "recall    = sk.metrics.recall_score(    y_true=df[\"true_opinion\"], y_pred=df[\"predicted_opinion\"])\n",
    "precision = sk.metrics.precision_score( y_true=df[\"true_opinion\"], y_pred=df[\"predicted_opinion\"])\n",
    "f1        = sk.metrics.f1_score(        y_true=df[\"true_opinion\"], y_pred=df[\"predicted_opinion\"])\n",
    "accuracy  = sk.metrics.accuracy_score(  y_true=df[\"true_opinion\"], y_pred=df[\"predicted_opinion\"])\n",
    "\n",
    "falseNegatives = df.query(\"`true_opinion` == 1 and `predicted_opinion` == 0\")\n",
    "falsePositives = df.query(\"`true_opinion` == 0 and `predicted_opinion` == 1\")\n",
    "corrects = df.query(\"`true_opinion` == `predicted_opinion`\")\n",
    "\n",
    "testFile = trainContainer.File\n",
    "#testFile = testContainer.File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>test file</th>\n",
       "      <td>assets/a3_train_final.tsv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model path</th>\n",
       "      <td>output/checkpoint-4500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>recall</th>\n",
       "      <td>0.9375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>precision</th>\n",
       "      <td>0.865385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f1</th>\n",
       "      <td>0.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>accuracy</th>\n",
       "      <td>0.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>#samples</th>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>#correct samples</th>\n",
       "      <td>90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>#false negatives</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>#false positives</th>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            0\n",
       "test file           assets/a3_train_final.tsv\n",
       "model path          output/checkpoint-4500   \n",
       "recall              0.9375                   \n",
       "precision           0.865385                 \n",
       "f1                  0.9                      \n",
       "accuracy            0.9                      \n",
       "#samples            100                      \n",
       "  #correct samples  90                       \n",
       "  #false negatives  3                        \n",
       "  #false positives  7                        "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'False Negatives'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>true_opinion</th>\n",
       "      <th>predicted_opinion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>all i can say is wow!!</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>odd, as a man living with hiv for 23 years, and vaccinated twice plus two boosters, my t cells were just tested and were by far the highest they've been in 15 years. one might almost think sherry tenpenny is lying.</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>everybody, finishing something quickly doesn't mean it is rushed</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                                                                                      text  \\\n",
       "13  all i can say is wow!!                                                                                                                                                                                                   \n",
       "27  odd, as a man living with hiv for 23 years, and vaccinated twice plus two boosters, my t cells were just tested and were by far the highest they've been in 15 years. one might almost think sherry tenpenny is lying.   \n",
       "60  everybody, finishing something quickly doesn't mean it is rushed                                                                                                                                                         \n",
       "\n",
       "    true_opinion  predicted_opinion  \n",
       "13  1             0                  \n",
       "27  1             0                  \n",
       "60  1             0                  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'False Positives'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>true_opinion</th>\n",
       "      <th>predicted_opinion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>vaccines do not cause autism. sure. i have autistic daughter. when she was 8 month she was vaccinated (6in1). next day she got fever, she got normal after 3-4 days. but after 2 weeks she stopped to laugh, look in the eyes and play with her toys. she became quiet, kind of thinking inside. now she's 10 yo. she can't talk and shows typical autism symptoms. i've done her hair analysis and it clearly showed that after vaccination the level of aluminium in her body raised multiple times above secure levels. continue to lie.</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>the fact that can use the logic of “this is a extremely rare side effect” and still force the vaccine but cant use the same logic of its extremely rare for me to die of covid regardless if i’m vaccinated is really aggravating</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>i was anti vaxxed and i have not gotten sick for 3 years before and how are wild animals ok if they were not vaccinated?</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>one thing about being a so called conspiracy theorist is that i will not have to worry about any of the side effects</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>im good, ill take my chances.</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           text  \\\n",
       "7   vaccines do not cause autism. sure. i have autistic daughter. when she was 8 month she was vaccinated (6in1). next day she got fever, she got normal after 3-4 days. but after 2 weeks she stopped to laugh, look in the eyes and play with her toys. she became quiet, kind of thinking inside. now she's 10 yo. she can't talk and shows typical autism symptoms. i've done her hair analysis and it clearly showed that after vaccination the level of aluminium in her body raised multiple times above secure levels. continue to lie.   \n",
       "31  the fact that can use the logic of “this is a extremely rare side effect” and still force the vaccine but cant use the same logic of its extremely rare for me to die of covid regardless if i’m vaccinated is really aggravating                                                                                                                                                                                                                                                                                                             \n",
       "35  i was anti vaxxed and i have not gotten sick for 3 years before and how are wild animals ok if they were not vaccinated?                                                                                                                                                                                                                                                                                                                                                                                                                      \n",
       "65  one thing about being a so called conspiracy theorist is that i will not have to worry about any of the side effects                                                                                                                                                                                                                                                                                                                                                                                                                          \n",
       "66  im good, ill take my chances.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 \n",
       "\n",
       "    true_opinion  predicted_opinion  \n",
       "7   0             1                  \n",
       "31  0             1                  \n",
       "35  0             1                  \n",
       "65  0             1                  \n",
       "66  0             1                  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'Correct'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>true_opinion</th>\n",
       "      <th>predicted_opinion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>getting mine in a week and i'm so stoked</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>the new classical vaccines ( without mrna and graphen) function perfectly as boosters so e.g. novavax, without devastating side effects.</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>i have had four covid shots and i feel great.</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>forcing healthy people to take medicine they don't need is a crime.</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>i'm so excited about the vaccine! i wish we could get it right now. this is fantastic news! merry christmas everyone! 🎆💖🎄☃️☮️😊</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                       text  \\\n",
       "0  getting mine in a week and i'm so stoked                                                                                                   \n",
       "1  the new classical vaccines ( without mrna and graphen) function perfectly as boosters so e.g. novavax, without devastating side effects.   \n",
       "2  i have had four covid shots and i feel great.                                                                                              \n",
       "3  forcing healthy people to take medicine they don't need is a crime.                                                                        \n",
       "4  i'm so excited about the vaccine! i wish we could get it right now. this is fantastic news! merry christmas everyone! 🎆💖🎄☃️☮️😊             \n",
       "\n",
       "   true_opinion  predicted_opinion  \n",
       "0  1             1                  \n",
       "1  1             1                  \n",
       "2  1             1                  \n",
       "3  0             0                  \n",
       "4  1             1                  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pd.set_option('display.max_colwidth', 0)\n",
    "\n",
    "testFrame = pd.DataFrame.from_dict({\n",
    "    \"test file\": [testFile],\n",
    "    \"model path\": [trainedPath],\n",
    "    \"recall\": [recall],\n",
    "    \"precision\": [precision],\n",
    "    \"f1\": [f1],\n",
    "    \"accuracy\": [accuracy],\n",
    "    \"#samples\": [df.shape[0]],\n",
    "    \"  #correct samples\": [corrects.shape[0]],\n",
    "    \"  #false negatives\": [falseNegatives.shape[0]],\n",
    "    \"  #false positives\": [falsePositives.shape[0]],\n",
    "}, orient=\"index\")\n",
    "display(testFrame)\n",
    "\n",
    "display(\"False Negatives\", falseNegatives.head())\n",
    "display(\"False Positives\", falsePositives.head())\n",
    "display(\"Correct\", corrects.head())\n",
    "\n",
    "import re\n",
    "def alphnum(s):\n",
    "    return re.sub(\"[^0-9a-zA-Z]+\", \"_\", s)\n",
    "\n",
    "try:\n",
    "    os.mkdir(\"test_results\")\n",
    "except Exception:\n",
    "    \"\"\n",
    "falseNegatives.to_csv(f\"test_results/{df.shape[0]}_{alphnum(testFile)}_{alphnum(trainedPath)}_False_Negatives.csv\")\n",
    "falsePositives.to_csv(f\"test_results/{df.shape[0]}_{alphnum(testFile)}_{alphnum(trainedPath)}_False_Positives.csv\")\n",
    "corrects.to_csv(f\"test_results/{df.shape[0]}_{alphnum(testFile)}_{alphnum(trainedPath)}_Correct.csv\")\n",
    "testFrame.to_csv(f\"test_results/{df.shape[0]}_{alphnum(testFile)}_{alphnum(trainedPath)}_STAT.csv\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importance scores\n",
    "captum usages is based off https://captum.ai/tutorials/Bert_SQUAD_Interpret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "imodel_path = \"output/checkpoint-4500\"\n",
    "\n",
    "# load model\n",
    "imodel = trainedModel\n",
    "imodel.to(device)\n",
    "imodel.eval()\n",
    "imodel.zero_grad()\n",
    "\n",
    "# load tokenizer\n",
    "itokenizer = bertTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def predict(inputs, token_type_ids=None, position_ids=None, attention_mask=None):\n",
    "    output = imodel(\n",
    "        inputs, \n",
    "        token_type_ids=token_type_ids,\n",
    "        position_ids=position_ids, \n",
    "        attention_mask=attention_mask, \n",
    "    )\n",
    "    return output.logits, output.logits\n",
    "\n",
    "def squad_pos_forward_func(inputs, token_type_ids=None, position_ids=None, attention_mask=None, position=0):\n",
    "    pred = predict(inputs,\n",
    "                   token_type_ids=token_type_ids,\n",
    "                   position_ids=position_ids,\n",
    "                   attention_mask=attention_mask)\n",
    "    pred = pred[position]\n",
    "    return pred.max(1).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "ref_token_id = itokenizer.pad_token_id # A token used for generating token reference\n",
    "sep_token_id = itokenizer.sep_token_id # A token used as a separator between question and text and it is also added to the end of the text.\n",
    "cls_token_id = itokenizer.cls_token_id # A token used for prepending to the concatenated question-text word sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def construct_input_ref_pair(question, ref_token_id, sep_token_id, cls_token_id):\n",
    "    question_ids = itokenizer.encode(question, add_special_tokens=False)\n",
    "\n",
    "    # construct input token ids\n",
    "    input_ids = [cls_token_id] + question_ids + [sep_token_id]\n",
    "\n",
    "    # construct reference token ids \n",
    "    ref_input_ids = [cls_token_id] + [ref_token_id] * len(question_ids) + [sep_token_id]\n",
    "\n",
    "    return torch.tensor([input_ids], device=device), torch.tensor([ref_input_ids], device=device), len(question_ids)\n",
    "\n",
    "def construct_input_ref_token_type_pair(input_ids, sep_ind=0):\n",
    "    seq_len = input_ids.size(1)\n",
    "    token_type_ids = torch.tensor([[0 if i <= sep_ind else 1 for i in range(seq_len)]], device=device)\n",
    "    ref_token_type_ids = torch.zeros_like(token_type_ids, device=device)# * -1\n",
    "    return token_type_ids, ref_token_type_ids\n",
    "\n",
    "def construct_input_ref_pos_id_pair(input_ids):\n",
    "    seq_length = input_ids.size(1)\n",
    "    position_ids = torch.arange(seq_length, dtype=torch.long, device=device)\n",
    "    # we could potentially also use random permutation with `torch.randperm(seq_length, device=device)`\n",
    "    ref_position_ids = torch.zeros(seq_length, dtype=torch.long, device=device)\n",
    "\n",
    "    position_ids = position_ids.unsqueeze(0).expand_as(input_ids)\n",
    "    ref_position_ids = ref_position_ids.unsqueeze(0).expand_as(input_ids)\n",
    "    return position_ids, ref_position_ids\n",
    "    \n",
    "def construct_attention_mask(input_ids):\n",
    "    return torch.ones_like(input_ids)\n",
    "\n",
    "def construct_whole_bert_embeddings(\n",
    "    input_ids, ref_input_ids, \n",
    "    token_type_ids=None, \n",
    "    ref_token_type_ids=None,\n",
    "    position_ids=None, \n",
    "    ref_position_ids=None\n",
    "):\n",
    "    input_embeddings = imodel.bert.embeddings(input_ids, token_type_ids=token_type_ids, position_ids=position_ids)\n",
    "    ref_input_embeddings = imodel.bert.embeddings(ref_input_ids, token_type_ids=ref_token_type_ids, position_ids=ref_position_ids)\n",
    "    \n",
    "    return input_embeddings, ref_input_embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def summarize_attributions(attributions):\n",
    "    attributions = attributions.sum(dim=-1).squeeze(0)\n",
    "    attributions = attributions / torch.norm(attributions)\n",
    "    return attributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "from captum.attr import visualization as viz\n",
    "from captum.attr import LayerConductance, LayerIntegratedGradients\n",
    "def getVisualizerFromSentence(text=None, trueClass=None):\n",
    "    if text == None:\n",
    "        return None\n",
    "    exampleText = text\n",
    "    input_ids, ref_input_ids, sep_id = construct_input_ref_pair(exampleText, ref_token_id, sep_token_id, cls_token_id)\n",
    "    token_type_ids, ref_token_type_ids = construct_input_ref_token_type_pair(input_ids, sep_id)\n",
    "    position_ids, ref_position_ids = construct_input_ref_pos_id_pair(input_ids)\n",
    "    attention_mask = construct_attention_mask(input_ids)\n",
    "\n",
    "    indices = input_ids[0].detach().tolist()\n",
    "    all_tokens = itokenizer.convert_ids_to_tokens(indices)\n",
    "\n",
    "    start_scores, end_scores = predict(\n",
    "        input_ids,\n",
    "        token_type_ids=token_type_ids,\n",
    "        position_ids=position_ids,\n",
    "        attention_mask=attention_mask\n",
    "    )\n",
    "\n",
    "    lig = LayerIntegratedGradients(squad_pos_forward_func, imodel.bert.embeddings) #.word_embeddings.weight\n",
    "\n",
    "    attributions_start, delta_start = lig.attribute(\n",
    "        inputs=input_ids,\n",
    "        baselines=ref_input_ids,\n",
    "        additional_forward_args=(token_type_ids, position_ids, attention_mask, 0),\n",
    "        return_convergence_delta=True\n",
    "    )\n",
    "\n",
    "    attributions_start_sum = summarize_attributions(attributions_start)\n",
    "\n",
    "    arg_tokens = itokenizer.encode(exampleText, add_special_tokens=False)\n",
    "    arg_end_ind = indices.index(arg_tokens[-1])\n",
    "    arg_start_ind = arg_end_ind - len(arg_tokens) + 1\n",
    "\n",
    "    start_position_vis = viz.VisualizationDataRecord(\n",
    "        attributions_start_sum,\n",
    "        torch.max(torch.softmax(start_scores[0], dim=0)),\n",
    "        torch.argmax(start_scores),\n",
    "        trueClass,\n",
    "        str(arg_start_ind),\n",
    "        attributions_start_sum.sum(),       \n",
    "        all_tokens,\n",
    "        delta_start\n",
    "    )\n",
    "    return start_position_vis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correct Positive classifications\n",
    "correctPos = [\n",
    "    getVisualizerFromSentence(trueClass=1, text=\"unicef you are doing and distributing vaccines booster covid-19 make for more confident and safe for people.thank you so much.\"),\n",
    "    getVisualizerFromSentence(trueClass=1, text=\"getting mine in a week and i'm so stoked\"),\n",
    "    getVisualizerFromSentence(trueClass=1, text=\"i'm so excited about the vaccine! i wish we could get it right now. this is fantastic news! merry christmas everyone! 🎆💖🎄☃️☮️😊\"),\n",
    "    getVisualizerFromSentence(trueClass=1, text=\"i will get the vaccine\"),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correct Negative classifications\n",
    "correctNeg = [\n",
    "    getVisualizerFromSentence(trueClass=0, text=\"forcing healthy people to take medicine they don't need is a crime.\"),\n",
    "    getVisualizerFromSentence(trueClass=0, text=\"some side effects are normal like death\"),\n",
    "    getVisualizerFromSentence(trueClass=0, text=\"vaccine are poison!\"),\n",
    "    getVisualizerFromSentence(trueClass=0, text=\"everyone should be refusing to be a guinea pig in this eugenics experiment\"),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# False Negatives\n",
    "falseNeg = [\n",
    "    getVisualizerFromSentence(trueClass=1, text=\"did you not read the article. it said vaccine is good\"),\n",
    "    getVisualizerFromSentence(trueClass=1, text=\"back in my day, we didn't have vaccines. we just died.\"),\n",
    "    getVisualizerFromSentence(trueClass=1, text=\"a similar vaccine, had a similar case during clinical trials\"),\n",
    "    getVisualizerFromSentence(trueClass=1, text=\"i got my moderna vaccine and now i'm a wifi hotspot\"),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# False Positives\n",
    "falsePos = [    \n",
    "    getVisualizerFromSentence(trueClass=0, text=\"i was anti vaxxed and i have not gotten sick for 3 years before and how are wild animals ok if they were not vaccinated?\"),\n",
    "    getVisualizerFromSentence(trueClass=0, text=\"one thing about being a so called conspiracy theorist is that i will not have to worry about any of the side effects\"),\n",
    "    getVisualizerFromSentence(trueClass=0, text=\"im good, ill take my chances.\"),\n",
    "    getVisualizerFromSentence(trueClass=0, text=\"we take other risks so taking this one shouldnt be a problem is the dumbest argument there is...\"),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table width: 100%><div style=\"border-top: 1px solid; margin-top: 5px;             padding-top: 5px; display: inline-block\"><b>Legend: </b><span style=\"display: inline-block; width: 10px; height: 10px;                 border: 1px solid; background-color:                 hsl(0, 75%, 60%)\"></span> Negative  <span style=\"display: inline-block; width: 10px; height: 10px;                 border: 1px solid; background-color:                 hsl(0, 75%, 100%)\"></span> Neutral  <span style=\"display: inline-block; width: 10px; height: 10px;                 border: 1px solid; background-color:                 hsl(120, 75%, 50%)\"></span> Positive  </div><tr><th>True Label</th><th>Predicted Label</th><th>Attribution Label</th><th>Attribution Score</th><th>Word Importance</th><tr><td><text style=\"padding-right:2em\"><b>1</b></text></td><td><text style=\"padding-right:2em\"><b>1 (1.00)</b></text></td><td><text style=\"padding-right:2em\"><b>-4</b></text></td><td><text style=\"padding-right:2em\"><b>2.43</b></text></td><td><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> [CLS]                    </font></mark><mark style=\"background-color: hsl(120, 75%, 99%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> unicef                    </font></mark><mark style=\"background-color: hsl(0, 75%, 98%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> you                    </font></mark><mark style=\"background-color: hsl(0, 75%, 95%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> are                    </font></mark><mark style=\"background-color: hsl(120, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> doing                    </font></mark><mark style=\"background-color: hsl(0, 75%, 94%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> and                    </font></mark><mark style=\"background-color: hsl(0, 75%, 98%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> distributing                    </font></mark><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> vaccines                    </font></mark><mark style=\"background-color: hsl(0, 75%, 98%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> booster                    </font></mark><mark style=\"background-color: hsl(0, 75%, 99%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> co                    </font></mark><mark style=\"background-color: hsl(0, 75%, 99%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> ##vid                    </font></mark><mark style=\"background-color: hsl(120, 75%, 99%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> -                    </font></mark><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> 19                    </font></mark><mark style=\"background-color: hsl(120, 75%, 98%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> make                    </font></mark><mark style=\"background-color: hsl(120, 75%, 97%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> for                    </font></mark><mark style=\"background-color: hsl(120, 75%, 91%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> more                    </font></mark><mark style=\"background-color: hsl(120, 75%, 90%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> confident                    </font></mark><mark style=\"background-color: hsl(120, 75%, 91%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> and                    </font></mark><mark style=\"background-color: hsl(120, 75%, 85%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> safe                    </font></mark><mark style=\"background-color: hsl(120, 75%, 82%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> for                    </font></mark><mark style=\"background-color: hsl(120, 75%, 90%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> people                    </font></mark><mark style=\"background-color: hsl(120, 75%, 79%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> .                    </font></mark><mark style=\"background-color: hsl(120, 75%, 74%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> thank                    </font></mark><mark style=\"background-color: hsl(120, 75%, 99%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> you                    </font></mark><mark style=\"background-color: hsl(120, 75%, 99%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> so                    </font></mark><mark style=\"background-color: hsl(120, 75%, 98%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> much                    </font></mark><mark style=\"background-color: hsl(120, 75%, 88%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> .                    </font></mark><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> [SEP]                    </font></mark></td><tr><tr><td><text style=\"padding-right:2em\"><b>1</b></text></td><td><text style=\"padding-right:2em\"><b>1 (1.00)</b></text></td><td><text style=\"padding-right:2em\"><b>1</b></text></td><td><text style=\"padding-right:2em\"><b>1.64</b></text></td><td><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> [CLS]                    </font></mark><mark style=\"background-color: hsl(0, 75%, 94%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> getting                    </font></mark><mark style=\"background-color: hsl(120, 75%, 83%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> mine                    </font></mark><mark style=\"background-color: hsl(120, 75%, 98%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> in                    </font></mark><mark style=\"background-color: hsl(120, 75%, 97%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> a                    </font></mark><mark style=\"background-color: hsl(120, 75%, 59%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> week                    </font></mark><mark style=\"background-color: hsl(120, 75%, 93%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> and                    </font></mark><mark style=\"background-color: hsl(120, 75%, 84%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> i                    </font></mark><mark style=\"background-color: hsl(0, 75%, 99%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> '                    </font></mark><mark style=\"background-color: hsl(0, 75%, 98%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> m                    </font></mark><mark style=\"background-color: hsl(120, 75%, 97%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> so                    </font></mark><mark style=\"background-color: hsl(120, 75%, 97%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> stoke                    </font></mark><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> ##d                    </font></mark><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> [SEP]                    </font></mark></td><tr><tr><td><text style=\"padding-right:2em\"><b>1</b></text></td><td><text style=\"padding-right:2em\"><b>1 (1.00)</b></text></td><td><text style=\"padding-right:2em\"><b>1</b></text></td><td><text style=\"padding-right:2em\"><b>4.14</b></text></td><td><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> [CLS]                    </font></mark><mark style=\"background-color: hsl(120, 75%, 91%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> i                    </font></mark><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> '                    </font></mark><mark style=\"background-color: hsl(0, 75%, 98%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> m                    </font></mark><mark style=\"background-color: hsl(120, 75%, 95%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> so                    </font></mark><mark style=\"background-color: hsl(120, 75%, 88%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> excited                    </font></mark><mark style=\"background-color: hsl(120, 75%, 99%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> about                    </font></mark><mark style=\"background-color: hsl(0, 75%, 96%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> the                    </font></mark><mark style=\"background-color: hsl(120, 75%, 96%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> vaccine                    </font></mark><mark style=\"background-color: hsl(120, 75%, 92%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> !                    </font></mark><mark style=\"background-color: hsl(120, 75%, 91%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> i                    </font></mark><mark style=\"background-color: hsl(120, 75%, 88%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> wish                    </font></mark><mark style=\"background-color: hsl(120, 75%, 92%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> we                    </font></mark><mark style=\"background-color: hsl(120, 75%, 96%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> could                    </font></mark><mark style=\"background-color: hsl(120, 75%, 91%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> get                    </font></mark><mark style=\"background-color: hsl(120, 75%, 90%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> it                    </font></mark><mark style=\"background-color: hsl(120, 75%, 98%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> right                    </font></mark><mark style=\"background-color: hsl(120, 75%, 95%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> now                    </font></mark><mark style=\"background-color: hsl(120, 75%, 93%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> .                    </font></mark><mark style=\"background-color: hsl(120, 75%, 91%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> this                    </font></mark><mark style=\"background-color: hsl(120, 75%, 86%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> is                    </font></mark><mark style=\"background-color: hsl(120, 75%, 79%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> fantastic                    </font></mark><mark style=\"background-color: hsl(120, 75%, 85%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> news                    </font></mark><mark style=\"background-color: hsl(120, 75%, 86%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> !                    </font></mark><mark style=\"background-color: hsl(120, 75%, 95%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> merry                    </font></mark><mark style=\"background-color: hsl(120, 75%, 90%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> christmas                    </font></mark><mark style=\"background-color: hsl(120, 75%, 93%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> everyone                    </font></mark><mark style=\"background-color: hsl(120, 75%, 94%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> !                    </font></mark><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> [UNK]                    </font></mark><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> [SEP]                    </font></mark></td><tr><tr><td><text style=\"padding-right:2em\"><b>1</b></text></td><td><text style=\"padding-right:2em\"><b>1 (1.00)</b></text></td><td><text style=\"padding-right:2em\"><b>1</b></text></td><td><text style=\"padding-right:2em\"><b>1.80</b></text></td><td><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> [CLS]                    </font></mark><mark style=\"background-color: hsl(120, 75%, 82%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> i                    </font></mark><mark style=\"background-color: hsl(120, 75%, 97%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> will                    </font></mark><mark style=\"background-color: hsl(120, 75%, 61%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> get                    </font></mark><mark style=\"background-color: hsl(120, 75%, 96%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> the                    </font></mark><mark style=\"background-color: hsl(120, 75%, 76%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> vaccine                    </font></mark><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> [SEP]                    </font></mark></td><tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table width: 100%><div style=\"border-top: 1px solid; margin-top: 5px;             padding-top: 5px; display: inline-block\"><b>Legend: </b><span style=\"display: inline-block; width: 10px; height: 10px;                 border: 1px solid; background-color:                 hsl(0, 75%, 60%)\"></span> Negative  <span style=\"display: inline-block; width: 10px; height: 10px;                 border: 1px solid; background-color:                 hsl(0, 75%, 100%)\"></span> Neutral  <span style=\"display: inline-block; width: 10px; height: 10px;                 border: 1px solid; background-color:                 hsl(120, 75%, 50%)\"></span> Positive  </div><tr><th>True Label</th><th>Predicted Label</th><th>Attribution Label</th><th>Attribution Score</th><th>Word Importance</th><tr><td><text style=\"padding-right:2em\"><b>0</b></text></td><td><text style=\"padding-right:2em\"><b>0 (0.98)</b></text></td><td><text style=\"padding-right:2em\"><b>1</b></text></td><td><text style=\"padding-right:2em\"><b>0.46</b></text></td><td><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> [CLS]                    </font></mark><mark style=\"background-color: hsl(120, 75%, 77%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> forcing                    </font></mark><mark style=\"background-color: hsl(120, 75%, 88%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> healthy                    </font></mark><mark style=\"background-color: hsl(120, 75%, 93%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> people                    </font></mark><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> to                    </font></mark><mark style=\"background-color: hsl(120, 75%, 92%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> take                    </font></mark><mark style=\"background-color: hsl(0, 75%, 88%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> medicine                    </font></mark><mark style=\"background-color: hsl(0, 75%, 85%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> they                    </font></mark><mark style=\"background-color: hsl(0, 75%, 92%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> don                    </font></mark><mark style=\"background-color: hsl(0, 75%, 94%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> '                    </font></mark><mark style=\"background-color: hsl(0, 75%, 99%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> t                    </font></mark><mark style=\"background-color: hsl(120, 75%, 82%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> need                    </font></mark><mark style=\"background-color: hsl(0, 75%, 92%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> is                    </font></mark><mark style=\"background-color: hsl(0, 75%, 99%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> a                    </font></mark><mark style=\"background-color: hsl(120, 75%, 81%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> crime                    </font></mark><mark style=\"background-color: hsl(120, 75%, 97%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> .                    </font></mark><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> [SEP]                    </font></mark></td><tr><tr><td><text style=\"padding-right:2em\"><b>0</b></text></td><td><text style=\"padding-right:2em\"><b>0 (0.97)</b></text></td><td><text style=\"padding-right:2em\"><b>1</b></text></td><td><text style=\"padding-right:2em\"><b>0.48</b></text></td><td><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> [CLS]                    </font></mark><mark style=\"background-color: hsl(0, 75%, 88%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> some                    </font></mark><mark style=\"background-color: hsl(120, 75%, 96%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> side                    </font></mark><mark style=\"background-color: hsl(120, 75%, 92%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> effects                    </font></mark><mark style=\"background-color: hsl(0, 75%, 83%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> are                    </font></mark><mark style=\"background-color: hsl(120, 75%, 98%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> normal                    </font></mark><mark style=\"background-color: hsl(120, 75%, 95%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> like                    </font></mark><mark style=\"background-color: hsl(120, 75%, 59%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> death                    </font></mark><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> [SEP]                    </font></mark></td><tr><tr><td><text style=\"padding-right:2em\"><b>0</b></text></td><td><text style=\"padding-right:2em\"><b>0 (1.00)</b></text></td><td><text style=\"padding-right:2em\"><b>1</b></text></td><td><text style=\"padding-right:2em\"><b>1.59</b></text></td><td><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> [CLS]                    </font></mark><mark style=\"background-color: hsl(120, 75%, 95%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> vaccine                    </font></mark><mark style=\"background-color: hsl(120, 75%, 73%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> are                    </font></mark><mark style=\"background-color: hsl(120, 75%, 59%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> poison                    </font></mark><mark style=\"background-color: hsl(120, 75%, 95%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> !                    </font></mark><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> [SEP]                    </font></mark></td><tr><tr><td><text style=\"padding-right:2em\"><b>0</b></text></td><td><text style=\"padding-right:2em\"><b>0 (1.00)</b></text></td><td><text style=\"padding-right:2em\"><b>1</b></text></td><td><text style=\"padding-right:2em\"><b>0.35</b></text></td><td><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> [CLS]                    </font></mark><mark style=\"background-color: hsl(120, 75%, 96%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> everyone                    </font></mark><mark style=\"background-color: hsl(0, 75%, 93%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> should                    </font></mark><mark style=\"background-color: hsl(120, 75%, 98%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> be                    </font></mark><mark style=\"background-color: hsl(120, 75%, 93%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> refusing                    </font></mark><mark style=\"background-color: hsl(120, 75%, 71%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> to                    </font></mark><mark style=\"background-color: hsl(120, 75%, 81%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> be                    </font></mark><mark style=\"background-color: hsl(120, 75%, 98%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> a                    </font></mark><mark style=\"background-color: hsl(120, 75%, 90%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> guinea                    </font></mark><mark style=\"background-color: hsl(0, 75%, 96%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> pig                    </font></mark><mark style=\"background-color: hsl(120, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> in                    </font></mark><mark style=\"background-color: hsl(0, 75%, 79%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> this                    </font></mark><mark style=\"background-color: hsl(120, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> eugen                    </font></mark><mark style=\"background-color: hsl(0, 75%, 96%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> ##ics                    </font></mark><mark style=\"background-color: hsl(0, 75%, 89%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> experiment                    </font></mark><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> [SEP]                    </font></mark></td><tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table width: 100%><div style=\"border-top: 1px solid; margin-top: 5px;             padding-top: 5px; display: inline-block\"><b>Legend: </b><span style=\"display: inline-block; width: 10px; height: 10px;                 border: 1px solid; background-color:                 hsl(0, 75%, 60%)\"></span> Negative  <span style=\"display: inline-block; width: 10px; height: 10px;                 border: 1px solid; background-color:                 hsl(0, 75%, 100%)\"></span> Neutral  <span style=\"display: inline-block; width: 10px; height: 10px;                 border: 1px solid; background-color:                 hsl(120, 75%, 50%)\"></span> Positive  </div><tr><th>True Label</th><th>Predicted Label</th><th>Attribution Label</th><th>Attribution Score</th><th>Word Importance</th><tr><td><text style=\"padding-right:2em\"><b>1</b></text></td><td><text style=\"padding-right:2em\"><b>0 (0.95)</b></text></td><td><text style=\"padding-right:2em\"><b>1</b></text></td><td><text style=\"padding-right:2em\"><b>0.25</b></text></td><td><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> [CLS]                    </font></mark><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> did                    </font></mark><mark style=\"background-color: hsl(0, 75%, 95%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> you                    </font></mark><mark style=\"background-color: hsl(0, 75%, 98%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> not                    </font></mark><mark style=\"background-color: hsl(0, 75%, 95%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> read                    </font></mark><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> the                    </font></mark><mark style=\"background-color: hsl(0, 75%, 94%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> article                    </font></mark><mark style=\"background-color: hsl(120, 75%, 99%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> .                    </font></mark><mark style=\"background-color: hsl(120, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> it                    </font></mark><mark style=\"background-color: hsl(0, 75%, 81%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> said                    </font></mark><mark style=\"background-color: hsl(120, 75%, 67%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> vaccine                    </font></mark><mark style=\"background-color: hsl(120, 75%, 96%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> is                    </font></mark><mark style=\"background-color: hsl(120, 75%, 77%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> good                    </font></mark><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> [SEP]                    </font></mark></td><tr><tr><td><text style=\"padding-right:2em\"><b>1</b></text></td><td><text style=\"padding-right:2em\"><b>0 (1.00)</b></text></td><td><text style=\"padding-right:2em\"><b>-3</b></text></td><td><text style=\"padding-right:2em\"><b>1.07</b></text></td><td><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> [CLS]                    </font></mark><mark style=\"background-color: hsl(120, 75%, 97%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> back                    </font></mark><mark style=\"background-color: hsl(0, 75%, 98%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> in                    </font></mark><mark style=\"background-color: hsl(120, 75%, 99%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> my                    </font></mark><mark style=\"background-color: hsl(0, 75%, 88%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> day                    </font></mark><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> ,                    </font></mark><mark style=\"background-color: hsl(0, 75%, 97%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> we                    </font></mark><mark style=\"background-color: hsl(120, 75%, 99%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> didn                    </font></mark><mark style=\"background-color: hsl(0, 75%, 96%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> '                    </font></mark><mark style=\"background-color: hsl(120, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> t                    </font></mark><mark style=\"background-color: hsl(120, 75%, 90%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> have                    </font></mark><mark style=\"background-color: hsl(120, 75%, 72%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> vaccines                    </font></mark><mark style=\"background-color: hsl(120, 75%, 98%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> .                    </font></mark><mark style=\"background-color: hsl(0, 75%, 96%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> we                    </font></mark><mark style=\"background-color: hsl(0, 75%, 98%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> just                    </font></mark><mark style=\"background-color: hsl(120, 75%, 68%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> died                    </font></mark><mark style=\"background-color: hsl(120, 75%, 88%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> .                    </font></mark><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> [SEP]                    </font></mark></td><tr><tr><td><text style=\"padding-right:2em\"><b>1</b></text></td><td><text style=\"padding-right:2em\"><b>0 (0.95)</b></text></td><td><text style=\"padding-right:2em\"><b>1</b></text></td><td><text style=\"padding-right:2em\"><b>0.87</b></text></td><td><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> [CLS]                    </font></mark><mark style=\"background-color: hsl(120, 75%, 78%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> a                    </font></mark><mark style=\"background-color: hsl(120, 75%, 81%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> similar                    </font></mark><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> vaccine                    </font></mark><mark style=\"background-color: hsl(0, 75%, 98%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> ,                    </font></mark><mark style=\"background-color: hsl(0, 75%, 80%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> had                    </font></mark><mark style=\"background-color: hsl(0, 75%, 96%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> a                    </font></mark><mark style=\"background-color: hsl(120, 75%, 79%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> similar                    </font></mark><mark style=\"background-color: hsl(120, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> case                    </font></mark><mark style=\"background-color: hsl(120, 75%, 86%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> during                    </font></mark><mark style=\"background-color: hsl(120, 75%, 90%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> clinical                    </font></mark><mark style=\"background-color: hsl(0, 75%, 92%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> trials                    </font></mark><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> [SEP]                    </font></mark></td><tr><tr><td><text style=\"padding-right:2em\"><b>1</b></text></td><td><text style=\"padding-right:2em\"><b>0 (0.88)</b></text></td><td><text style=\"padding-right:2em\"><b>1</b></text></td><td><text style=\"padding-right:2em\"><b>0.47</b></text></td><td><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> [CLS]                    </font></mark><mark style=\"background-color: hsl(120, 75%, 87%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> i                    </font></mark><mark style=\"background-color: hsl(120, 75%, 78%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> got                    </font></mark><mark style=\"background-color: hsl(120, 75%, 86%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> my                    </font></mark><mark style=\"background-color: hsl(120, 75%, 83%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> modern                    </font></mark><mark style=\"background-color: hsl(120, 75%, 97%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> ##a                    </font></mark><mark style=\"background-color: hsl(120, 75%, 91%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> vaccine                    </font></mark><mark style=\"background-color: hsl(0, 75%, 95%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> and                    </font></mark><mark style=\"background-color: hsl(0, 75%, 75%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> now                    </font></mark><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> i                    </font></mark><mark style=\"background-color: hsl(120, 75%, 99%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> '                    </font></mark><mark style=\"background-color: hsl(120, 75%, 99%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> m                    </font></mark><mark style=\"background-color: hsl(0, 75%, 99%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> a                    </font></mark><mark style=\"background-color: hsl(0, 75%, 98%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> wi                    </font></mark><mark style=\"background-color: hsl(0, 75%, 97%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> ##fi                    </font></mark><mark style=\"background-color: hsl(0, 75%, 96%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> hot                    </font></mark><mark style=\"background-color: hsl(0, 75%, 99%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> ##sp                    </font></mark><mark style=\"background-color: hsl(0, 75%, 96%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> ##ot                    </font></mark><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> [SEP]                    </font></mark></td><tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table width: 100%><div style=\"border-top: 1px solid; margin-top: 5px;             padding-top: 5px; display: inline-block\"><b>Legend: </b><span style=\"display: inline-block; width: 10px; height: 10px;                 border: 1px solid; background-color:                 hsl(0, 75%, 60%)\"></span> Negative  <span style=\"display: inline-block; width: 10px; height: 10px;                 border: 1px solid; background-color:                 hsl(0, 75%, 100%)\"></span> Neutral  <span style=\"display: inline-block; width: 10px; height: 10px;                 border: 1px solid; background-color:                 hsl(120, 75%, 50%)\"></span> Positive  </div><tr><th>True Label</th><th>Predicted Label</th><th>Attribution Label</th><th>Attribution Score</th><th>Word Importance</th><tr><td><text style=\"padding-right:2em\"><b>0</b></text></td><td><text style=\"padding-right:2em\"><b>1 (0.88)</b></text></td><td><text style=\"padding-right:2em\"><b>1</b></text></td><td><text style=\"padding-right:2em\"><b>0.11</b></text></td><td><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> [CLS]                    </font></mark><mark style=\"background-color: hsl(0, 75%, 98%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> i                    </font></mark><mark style=\"background-color: hsl(0, 75%, 97%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> was                    </font></mark><mark style=\"background-color: hsl(120, 75%, 53%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> anti                    </font></mark><mark style=\"background-color: hsl(0, 75%, 99%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> va                    </font></mark><mark style=\"background-color: hsl(0, 75%, 96%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> ##xx                    </font></mark><mark style=\"background-color: hsl(120, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> ##ed                    </font></mark><mark style=\"background-color: hsl(120, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> and                    </font></mark><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> i                    </font></mark><mark style=\"background-color: hsl(120, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> have                    </font></mark><mark style=\"background-color: hsl(120, 75%, 99%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> not                    </font></mark><mark style=\"background-color: hsl(0, 75%, 97%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> gotten                    </font></mark><mark style=\"background-color: hsl(0, 75%, 97%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> sick                    </font></mark><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> for                    </font></mark><mark style=\"background-color: hsl(0, 75%, 98%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> 3                    </font></mark><mark style=\"background-color: hsl(120, 75%, 96%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> years                    </font></mark><mark style=\"background-color: hsl(120, 75%, 99%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> before                    </font></mark><mark style=\"background-color: hsl(120, 75%, 98%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> and                    </font></mark><mark style=\"background-color: hsl(0, 75%, 98%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> how                    </font></mark><mark style=\"background-color: hsl(0, 75%, 99%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> are                    </font></mark><mark style=\"background-color: hsl(0, 75%, 96%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> wild                    </font></mark><mark style=\"background-color: hsl(0, 75%, 99%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> animals                    </font></mark><mark style=\"background-color: hsl(0, 75%, 96%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> ok                    </font></mark><mark style=\"background-color: hsl(0, 75%, 99%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> if                    </font></mark><mark style=\"background-color: hsl(0, 75%, 99%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> they                    </font></mark><mark style=\"background-color: hsl(120, 75%, 99%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> were                    </font></mark><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> not                    </font></mark><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> va                    </font></mark><mark style=\"background-color: hsl(0, 75%, 99%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> ##cci                    </font></mark><mark style=\"background-color: hsl(120, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> ##nated                    </font></mark><mark style=\"background-color: hsl(0, 75%, 99%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> ?                    </font></mark><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> [SEP]                    </font></mark></td><tr><tr><td><text style=\"padding-right:2em\"><b>0</b></text></td><td><text style=\"padding-right:2em\"><b>1 (0.88)</b></text></td><td><text style=\"padding-right:2em\"><b>1</b></text></td><td><text style=\"padding-right:2em\"><b>0.21</b></text></td><td><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> [CLS]                    </font></mark><mark style=\"background-color: hsl(120, 75%, 90%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> one                    </font></mark><mark style=\"background-color: hsl(0, 75%, 96%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> thing                    </font></mark><mark style=\"background-color: hsl(120, 75%, 96%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> about                    </font></mark><mark style=\"background-color: hsl(0, 75%, 98%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> being                    </font></mark><mark style=\"background-color: hsl(0, 75%, 95%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> a                    </font></mark><mark style=\"background-color: hsl(0, 75%, 95%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> so                    </font></mark><mark style=\"background-color: hsl(0, 75%, 78%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> called                    </font></mark><mark style=\"background-color: hsl(0, 75%, 97%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> conspiracy                    </font></mark><mark style=\"background-color: hsl(120, 75%, 72%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> theorist                    </font></mark><mark style=\"background-color: hsl(120, 75%, 97%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> is                    </font></mark><mark style=\"background-color: hsl(120, 75%, 86%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> that                    </font></mark><mark style=\"background-color: hsl(0, 75%, 98%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> i                    </font></mark><mark style=\"background-color: hsl(0, 75%, 98%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> will                    </font></mark><mark style=\"background-color: hsl(120, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> not                    </font></mark><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> have                    </font></mark><mark style=\"background-color: hsl(120, 75%, 94%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> to                    </font></mark><mark style=\"background-color: hsl(0, 75%, 94%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> worry                    </font></mark><mark style=\"background-color: hsl(120, 75%, 92%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> about                    </font></mark><mark style=\"background-color: hsl(120, 75%, 97%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> any                    </font></mark><mark style=\"background-color: hsl(120, 75%, 95%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> of                    </font></mark><mark style=\"background-color: hsl(120, 75%, 93%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> the                    </font></mark><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> side                    </font></mark><mark style=\"background-color: hsl(0, 75%, 94%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> effects                    </font></mark><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> [SEP]                    </font></mark></td><tr><tr><td><text style=\"padding-right:2em\"><b>0</b></text></td><td><text style=\"padding-right:2em\"><b>1 (0.99)</b></text></td><td><text style=\"padding-right:2em\"><b>1</b></text></td><td><text style=\"padding-right:2em\"><b>1.17</b></text></td><td><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> [CLS]                    </font></mark><mark style=\"background-color: hsl(120, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> im                    </font></mark><mark style=\"background-color: hsl(120, 75%, 93%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> good                    </font></mark><mark style=\"background-color: hsl(120, 75%, 93%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> ,                    </font></mark><mark style=\"background-color: hsl(120, 75%, 79%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> ill                    </font></mark><mark style=\"background-color: hsl(120, 75%, 76%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> take                    </font></mark><mark style=\"background-color: hsl(120, 75%, 80%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> my                    </font></mark><mark style=\"background-color: hsl(0, 75%, 77%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> chances                    </font></mark><mark style=\"background-color: hsl(120, 75%, 95%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> .                    </font></mark><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> [SEP]                    </font></mark></td><tr><tr><td><text style=\"padding-right:2em\"><b>0</b></text></td><td><text style=\"padding-right:2em\"><b>1 (0.98)</b></text></td><td><text style=\"padding-right:2em\"><b>-1</b></text></td><td><text style=\"padding-right:2em\"><b>0.87</b></text></td><td><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> [CLS]                    </font></mark><mark style=\"background-color: hsl(0, 75%, 99%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> we                    </font></mark><mark style=\"background-color: hsl(0, 75%, 97%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> take                    </font></mark><mark style=\"background-color: hsl(0, 75%, 97%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> other                    </font></mark><mark style=\"background-color: hsl(120, 75%, 80%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> risks                    </font></mark><mark style=\"background-color: hsl(0, 75%, 90%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> so                    </font></mark><mark style=\"background-color: hsl(120, 75%, 94%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> taking                    </font></mark><mark style=\"background-color: hsl(120, 75%, 67%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> this                    </font></mark><mark style=\"background-color: hsl(120, 75%, 95%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> one                    </font></mark><mark style=\"background-color: hsl(0, 75%, 92%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> shouldn                    </font></mark><mark style=\"background-color: hsl(0, 75%, 96%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> ##t                    </font></mark><mark style=\"background-color: hsl(120, 75%, 89%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> be                    </font></mark><mark style=\"background-color: hsl(120, 75%, 97%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> a                    </font></mark><mark style=\"background-color: hsl(0, 75%, 98%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> problem                    </font></mark><mark style=\"background-color: hsl(0, 75%, 96%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> is                    </font></mark><mark style=\"background-color: hsl(0, 75%, 95%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> the                    </font></mark><mark style=\"background-color: hsl(0, 75%, 98%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> dumb                    </font></mark><mark style=\"background-color: hsl(120, 75%, 93%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> ##est                    </font></mark><mark style=\"background-color: hsl(0, 75%, 93%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> argument                    </font></mark><mark style=\"background-color: hsl(120, 75%, 97%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> there                    </font></mark><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> is                    </font></mark><mark style=\"background-color: hsl(120, 75%, 90%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> .                    </font></mark><mark style=\"background-color: hsl(120, 75%, 94%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> .                    </font></mark><mark style=\"background-color: hsl(120, 75%, 99%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> .                    </font></mark><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> [SEP]                    </font></mark></td><tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "viz.visualize_text(correctPos)\n",
    "viz.visualize_text(correctNeg)\n",
    "viz.visualize_text(falseNeg)\n",
    "viz.visualize_text(falsePos)\n",
    "_=1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d8055ec17fc34cb0b8458f3f0e4a59cee2796a9a848309c3ef54794b90a4b01d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
