{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- How much consensus is there between annotators of the dataset? Do you think the data is reliable?\n",
    "- How do you represent your data as features?\n",
    "- Did you process the features in any way?\n",
    "- How did you select which learning algorithms to use?\n",
    "- Did you try to tune the hyperparameters of the learning algorithm, and in that case how?\n",
    "- How do you evaluate the quality of your system?\n",
    "- How well does your system compare to a trivial baseline?\n",
    "- Can you say anything about the errors that the system makes? For a classification task, you may consider a confusion matrix. It is also probably meaningful to include selected errors and comment on what might have gone wrong.\n",
    "- Is it possible to say something about which features the model considers important? (Whether this is possible depends on the type of classifier you are using.) \n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How much consensus is there between annotators of the dataset? Do you think the data is reliable\n",
    "The annotated data is very sparse, there is a great deal of variation between the numbers annotators. There is also no way to see who made what annotation.\n",
    "\n",
    "It is not clear how -1 should be handled. From a human perspective you can argue `0/-1` communicates more uncertaincy than just `0`. To determinte the approach some different methods were tested by measuring thier resulting Krippendorff Alpha as the kappa metric. \n",
    "\n",
    "| Handling of -1              | Krippendorff Alpha |\n",
    "| --------------------------- | ------------------ |\n",
    "| As its own class            | 0.5894 |\n",
    "| Replacing with null         | 0.8798 |\n",
    "| Replacing with 0/1 at random</br>50%/50%                          | 0.8798 |\n",
    "| Replacing with 0/1 at random</br>based of the global distribution | 0.8798 |\n",
    "| Replacing with 0            | 0.8043 |\n",
    "| Replacing with 1            | 0.7892 |\n",
    "\n",
    "Because null and random gives no difference, at least within floating point rounding errors, we conclude -1 annotations does not to matter for the \"true\" class of the item. Therefore -1 is replaced with null as a preproccessing step.\n",
    "\n",
    "### Result\n",
    "A kappa of 0.88 is very high*, there is much consenus. Reliability should be good as classification should not hinge much on personal belives but because all anntators are Chalmers/GU students that go the same course there could be quite high bias in the data regardless.\n",
    "(https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3900052/)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How do you represent your data as features?\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d8055ec17fc34cb0b8458f3f0e4a59cee2796a9a848309c3ef54794b90a4b01d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
